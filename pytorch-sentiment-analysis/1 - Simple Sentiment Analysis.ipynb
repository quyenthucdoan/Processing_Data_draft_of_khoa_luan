{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Simple Sentiment Analysis\n",
    "\n",
    "In this series we'll be building a machine learning model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "\n",
    "In this first notebook, we'll start very simple to understand the general concepts whilst not really caring about good results. Further notebooks will build on this knowledge and we'll actually get good results.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "We'll be using a **recurrent neural network** (RNN) as they are commonly used in analysing sequences. An RNN takes in sequence of words, $X=\\{x_1, ..., x_T\\}$, one at a time, and produces a _hidden state_, $h$, for each word. We use the RNN _recurrently_ by feeding in the current word $x_t$ as well as the hidden state from the previous word, $h_{t-1}$, to produce the next hidden state, $h_t$. \n",
    "\n",
    "$$h_t = \\text{RNN}(x_t, h_{t-1})$$\n",
    "\n",
    "Once we have our final hidden state, $h_T$, (from feeding in the last word in the sequence, $x_T$) we feed it through a linear layer, $f$, (also known as a fully connected layer), to receive our predicted sentiment, $\\hat{y} = f(h_T)$.\n",
    "\n",
    "Below shows an example sentence, with the RNN predicting zero, which indicates a negative sentiment. The RNN is shown in orange and the linear layer shown in silver. Note that we use the same RNN for every word, i.e. it has the same parameters. The initial hidden state, $h_0$, is a tensor initialized to all zeros. \n",
    "\n",
    "![](assets/sentiment1.png)\n",
    "\n",
    "**Note:** some layers and steps have been omitted from the diagram, but these will be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "One of the main concepts of TorchText is the `Field`. These define how your data should be processed. In our sentiment classification task the data consists of both the raw string of the review and the sentiment, either \"pos\" or \"neg\".\n",
    "\n",
    "The parameters of a `Field` specify how the data should be processed. \n",
    "\n",
    "We use the `TEXT` field to define how the review should be processed, and the `LABEL` field to process the sentiment. \n",
    "\n",
    "Our `TEXT` field has `tokenize='spacy'` as an argument. This defines that the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the [spaCy](https://spacy.io) tokenizer. If no `tokenize` argument is passed, the default is simply splitting the string on spaces. We also need to specify a `tokenizer_language` which tells torchtext which spaCy model to use. We use the `en_core_web_sm` model which has to be downloaded with `python -m spacy download en_core_web_sm` before you run this notebook!\n",
    "\n",
    "`LABEL` is defined by a `LabelField`, a special subset of the `Field` class specifically used for handling labels. We will explain the `dtype` argument later.\n",
    "\n",
    "For more on `Fields`, go [here](https://github.com/pytorch/text/blob/master/torchtext/data/field.py).\n",
    "\n",
    "We also set the random seeds for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pywin32 -U\n",
    "# !pip install spacy\n",
    "\n",
    "# !pip install torchtext\n",
    "# !pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', \n",
    "                  tokenizer_language = 'en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another handy feature of TorchText is that it has support for common datasets used in natural language processing (NLP). \n",
    "\n",
    "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as `torchtext.datasets` objects. It process the data using the `Fields` we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many examples are in each split by checking their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examples': [<torchtext.legacy.data.example.Example at 0x2060ed9e0a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20610bf5250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ea90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060d79ed00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060d79e8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ec10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ebe0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9efd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ed30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ee50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ed00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9ed90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2060ed9e670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112af9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afa00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afaf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afb80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afb20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afc70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afd00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afa30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afdc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afd30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afe50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112afe20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112aff10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112affa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112aff70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112af790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112af880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112af910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206112af760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127881f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127882e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127882b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127883d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127884f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127885e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127885b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127886a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127886d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127887c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127888b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127889a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788b80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788c70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788dc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612788040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206127880d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b91f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b92b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b93d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b94c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b96d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b97f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b99a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9bb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9c70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9df0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b90a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206128b9100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a1f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a4c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a5e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a6d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296aac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ab80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ab50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296abe0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296aca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296acd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ac40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ad30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ad90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ae50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296ae80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296af10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296af40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296aeb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061296a160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c3a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c3d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c4c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c5e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c6d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3ca00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3ca90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cb20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cbe0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cc40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cc70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3ccd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cd60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cdc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cdf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3ce50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cf10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3ceb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3cfa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c0a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c1c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c1f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612a3c040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af22b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af24f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af24c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af25e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af28b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2bb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2c40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2df0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2e80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612af2130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd41f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd42b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd44f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd45e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd46d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd47f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd48e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4bb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4c10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4dc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4fd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd40d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612bd4040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab1c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab3a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab6d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612caba90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabbb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabc10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabc70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabd00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabd60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabe50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabe20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabe80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabeb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabfd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cabfa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab0a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612cab160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e6d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e7c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ea60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ea90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5eac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5eb20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5eb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ebb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ec70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ebe0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ed60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ed90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ed30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5edf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ef10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5ef40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5eee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e0d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612d5e190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e341f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e342b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e343a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e343d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e344c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e345e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e346d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e347f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e348e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e349d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34c10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34c70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34e80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e340a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20612e34130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce3a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce7c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce8e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cea60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cea90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ceb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ceb20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cec10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cec40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ceca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ced00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ced90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ced60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cee20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ceeb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cef40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cef10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140cefa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce0a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206140ce040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c1c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c3d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c5e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c7c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418ca90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cbb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cb80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cc10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cc40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418ccd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cd30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cd90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418ce50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418ce20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418ceb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cf40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418cfa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061418c130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c22e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c23a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c25b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c26d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c27f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c28b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c29d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2bb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2c40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2dc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2e50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2e80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c20a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c2130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206143c21f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c1c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c3d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c4c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c6d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c8e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448ca60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cbe0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cc70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448ccd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cd60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cd00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cdc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448ce50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448ceb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cf10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448cfa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c0d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061448c070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145121c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145122b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145122e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145123d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145124f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145126a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145129d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512df0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512e80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145120d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614512070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c11c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c12b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c14f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c15b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c16a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c17f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c19d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1c40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1df0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1e80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206145c1040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b3a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b5e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468ba30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468ba90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468baf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bbb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bc40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bd00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bd60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bd30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468be20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468be80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468beb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bf10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468bfa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x2061468b160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147451f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147453a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147455b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147456a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147456d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147458b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147459a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745bb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614745040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f31c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f32e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f33a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f33d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f34f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f35b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f36d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f37f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f38e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f39d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3c10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3c40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3df0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206147f3040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a51f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a52e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a54c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a54f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a55e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a55b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a56d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5a90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5b50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5c10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5dc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5e20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5fd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a51c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a5040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x206148a50a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f1f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f340>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f3d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f4c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f5e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f760>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f790>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f940>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fa00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fa60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fa90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fb80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fc10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fc70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fcd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fdc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fd60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fdf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9fe50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9ff10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9ff40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9ffd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f0d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614a9f160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b461c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b462e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b463a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b465b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b466a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b467c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b467f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b468e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46a00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46ac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46b80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46c10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46ca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46d90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46dc0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46e50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46f10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46f40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46fd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46130>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b46040>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614b460d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef190>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef220>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef4f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef5b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef670>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef7c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef8e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef9a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefa90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefa30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefb20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefbb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefc10>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefc40>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefca0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefd00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefd90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefdf0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefe20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefe80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cefee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614ceff70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614ceffa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614cef0d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e841f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e842e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84250>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84310>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e843d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84400>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84430>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e844c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84550>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e845b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e846a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e846d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84700>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84880>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84850>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e848b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e849a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84a30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84a60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84af0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84b20>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84b80>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84be0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84c70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84cd0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84d30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84d00>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84d60>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84e50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84eb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84ee0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84f70>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84fa0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84070>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e84160>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614e841c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f100>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f2b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f280>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f2e0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f370>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f3d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f460>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f490>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f4c0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f520>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f580>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f610>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f640>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f6a0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f730>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f7f0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f8b0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f910>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f820>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f970>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2f9d0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fa30>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fa90>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fac0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fb50>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fbb0>,\n",
       "  <torchtext.legacy.data.example.Example at 0x20614f2fc10>,\n",
       "  ...],\n",
       " 'fields': {'text': <torchtext.legacy.data.field.Field at 0x2064e574430>,\n",
       "  'label': <torchtext.legacy.data.field.LabelField at 0x20638b06f70>}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'pos',\n",
      " 'text': ['Bromwell',\n",
      "          'High',\n",
      "          'is',\n",
      "          'a',\n",
      "          'cartoon',\n",
      "          'comedy',\n",
      "          '.',\n",
      "          'It',\n",
      "          'ran',\n",
      "          'at',\n",
      "          'the',\n",
      "          'same',\n",
      "          'time',\n",
      "          'as',\n",
      "          'some',\n",
      "          'other',\n",
      "          'programs',\n",
      "          'about',\n",
      "          'school',\n",
      "          'life',\n",
      "          ',',\n",
      "          'such',\n",
      "          'as',\n",
      "          '\"',\n",
      "          'Teachers',\n",
      "          '\"',\n",
      "          '.',\n",
      "          'My',\n",
      "          '35',\n",
      "          'years',\n",
      "          'in',\n",
      "          'the',\n",
      "          'teaching',\n",
      "          'profession',\n",
      "          'lead',\n",
      "          'me',\n",
      "          'to',\n",
      "          'believe',\n",
      "          'that',\n",
      "          'Bromwell',\n",
      "          'High',\n",
      "          \"'s\",\n",
      "          'satire',\n",
      "          'is',\n",
      "          'much',\n",
      "          'closer',\n",
      "          'to',\n",
      "          'reality',\n",
      "          'than',\n",
      "          'is',\n",
      "          '\"',\n",
      "          'Teachers',\n",
      "          '\"',\n",
      "          '.',\n",
      "          'The',\n",
      "          'scramble',\n",
      "          'to',\n",
      "          'survive',\n",
      "          'financially',\n",
      "          ',',\n",
      "          'the',\n",
      "          'insightful',\n",
      "          'students',\n",
      "          'who',\n",
      "          'can',\n",
      "          'see',\n",
      "          'right',\n",
      "          'through',\n",
      "          'their',\n",
      "          'pathetic',\n",
      "          'teachers',\n",
      "          \"'\",\n",
      "          'pomp',\n",
      "          ',',\n",
      "          'the',\n",
      "          'pettiness',\n",
      "          'of',\n",
      "          'the',\n",
      "          'whole',\n",
      "          'situation',\n",
      "          ',',\n",
      "          'all',\n",
      "          'remind',\n",
      "          'me',\n",
      "          'of',\n",
      "          'the',\n",
      "          'schools',\n",
      "          'I',\n",
      "          'knew',\n",
      "          'and',\n",
      "          'their',\n",
      "          'students',\n",
      "          '.',\n",
      "          'When',\n",
      "          'I',\n",
      "          'saw',\n",
      "          'the',\n",
      "          'episode',\n",
      "          'in',\n",
      "          'which',\n",
      "          'a',\n",
      "          'student',\n",
      "          'repeatedly',\n",
      "          'tried',\n",
      "          'to',\n",
      "          'burn',\n",
      "          'down',\n",
      "          'the',\n",
      "          'school',\n",
      "          ',',\n",
      "          'I',\n",
      "          'immediately',\n",
      "          'recalled',\n",
      "          '.........',\n",
      "          'at',\n",
      "          '..........',\n",
      "          'High',\n",
      "          '.',\n",
      "          'A',\n",
      "          'classic',\n",
      "          'line',\n",
      "          ':',\n",
      "          'INSPECTOR',\n",
      "          ':',\n",
      "          'I',\n",
      "          \"'m\",\n",
      "          'here',\n",
      "          'to',\n",
      "          'sack',\n",
      "          'one',\n",
      "          'of',\n",
      "          'your',\n",
      "          'teachers',\n",
      "          '.',\n",
      "          'STUDENT',\n",
      "          ':',\n",
      "          'Welcome',\n",
      "          'to',\n",
      "          'Bromwell',\n",
      "          'High',\n",
      "          '.',\n",
      "          'I',\n",
      "          'expect',\n",
      "          'that',\n",
      "          'many',\n",
      "          'adults',\n",
      "          'of',\n",
      "          'my',\n",
      "          'age',\n",
      "          'think',\n",
      "          'that',\n",
      "          'Bromwell',\n",
      "          'High',\n",
      "          'is',\n",
      "          'far',\n",
      "          'fetched',\n",
      "          '.',\n",
      "          'What',\n",
      "          'a',\n",
      "          'pity',\n",
      "          'that',\n",
      "          'it',\n",
      "          'is',\n",
      "          \"n't\",\n",
      "          '!']}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDb dataset only has train/test splits, so we need to create a validation set. We can do this with the `.split()` method. \n",
    "\n",
    "By default this splits 70/30, however by passing a `split_ratio` argument, we can change the ratio of the split, i.e. a `split_ratio` of 0.8 would mean 80% of the examples make up the training set and 20% make up the validation set. \n",
    "\n",
    "We also pass our random seed to the `random_state` argument, ensuring that we get the same train/validation split each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll view how many examples are in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to build a _vocabulary_. This is a effectively a look up table where every unique word in your data set has a corresponding _index_ (an integer).\n",
    "\n",
    "We do this as our machine learning model cannot operate on strings, only numbers. Each _index_ is used to construct a _one-hot_ vector for each word. A one-hot vector is a vector where all of the elements are 0, except one, which is 1, and dimensionality is the total number of unique words in your vocabulary, commonly denoted by $V$.\n",
    "\n",
    "![](assets/sentiment5.png)\n",
    "\n",
    "The number of unique words in our training set is over 100,000, which means that our one-hot vectors will have over 100,000 dimensions! This will make training slow and possibly won't fit onto your GPU (if you're using one). \n",
    "\n",
    "There are two ways effectively cut down our vocabulary, we can either only take the top $n$ most common words or ignore words that appear less than $m$ times. We'll do the former, only keeping the top 25,000 words.\n",
    "\n",
    "What do we do with words that appear in examples but we have cut from the vocabulary? We replace them with a special _unknown_ or `<unk>` token. For example, if the sentence was \"This film is great and I love it\" but the word \"love\" was not in the vocabulary, it would become \"This film is great and I `<unk>` it\".\n",
    "\n",
    "The following builds the vocabulary, only keeping the most common `max_size` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we only build the vocabulary on the training set? When testing any machine learning system you do not want to look at the test set in any way. We do not include the validation set as we want it to reflect the test set as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the vocab size 25002 and not 25000? One of the addition tokens is the `<unk>` token and the other is a `<pad>` token.\n",
    "\n",
    "When we feed sentences into our model, we feed a _batch_ of them at a time, i.e. more than one at a time, and all sentences in the batch need to be the same size. Thus, to ensure each sentence in the batch is the same size, any shorter than the longest within the batch are padded.\n",
    "\n",
    "![](assets/sentiment6.png)\n",
    "\n",
    "We can also view the most common words in the vocabulary and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 203566), (',', 192495), ('.', 165539), ('and', 109443), ('a', 109116), ('of', 100702), ('to', 93766), ('is', 76328), ('in', 61255), ('I', 54004), ('it', 53508), ('that', 49187), ('\"', 44285), (\"'s\", 43329), ('this', 42445), ('-', 37165), ('/><br', 35752), ('was', 35034), ('as', 30384), ('with', 29774)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the vocabulary directly using either the `stoi` (**s**tring **to** **i**nt) or `itos` (**i**nt **to**  **s**tring) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the labels, ensuring 0 is for negative and 1 is for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of preparing the data is creating the iterators. We iterate over these in the training/evaluation loop, and they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
    "\n",
    "We'll use a `BucketIterator` which is a special type of iterator that will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
    "\n",
    "We also want to place the tensors returned by the iterator on the GPU (if you're using one). PyTorch handles this using `torch.device`, we then pass this device to the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "The next stage is building the model that we'll eventually train and evaluate. \n",
    "\n",
    "There is a small amount of boilerplate code when creating models in PyTorch, note how our `RNN` class is a sub-class of `nn.Module` and the use of `super`.\n",
    "\n",
    "Within the `__init__` we define the _layers_ of the module. Our three layers are an _embedding_ layer, our RNN, and a _linear_ layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
    "\n",
    "The embedding layer is used to transform our sparse one-hot vector (sparse as most of the elements are 0) into a dense embedding vector (dense as the dimensionality is a lot smaller and all the elements are real numbers). This embedding layer is simply a single fully connected layer. As well as reducing the dimensionality of the input to the RNN, there is the theory that words which have similar impact on the sentiment of the review are mapped close together in this dense vector space. For more information about word embeddings, see [here](https://monkeylearn.com/blog/word-embeddings-transform-text-numbers/).\n",
    "\n",
    "The RNN layer is our RNN which takes in our dense vector and the previous hidden state $h_{t-1}$, which it uses to calculate the next hidden state, $h_t$.\n",
    "\n",
    "![](assets/sentiment7.png)\n",
    "\n",
    "Finally, the linear layer takes the final hidden state and feeds it through a fully connected layer, $f(h_T)$, transforming it to the correct output dimension.\n",
    "\n",
    "The `forward` method is called when we feed examples into our model.\n",
    "\n",
    "Each batch, `text`, is a tensor of size _**[sentence length, batch size]**_. That is a batch of sentences, each having each word converted into a one-hot vector. \n",
    "\n",
    "You may notice that this tensor should have another dimension due to the one-hot vectors, however PyTorch conveniently stores a one-hot vector as it's index value, i.e. the tensor representing a sentence is just a tensor of the indexes for each token in that sentence. The act of converting a list of tokens into a list of indexes is commonly called *numericalizing*.\n",
    "\n",
    "The input batch is then passed through the embedding layer to get `embedded`, which gives us a dense vector representation of our sentences. `embedded` is a tensor of size _**[sentence length, batch size, embedding dim]**_.\n",
    "\n",
    "`embedded` is then fed into the RNN. In some frameworks you must feed the initial hidden state, $h_0$, into the RNN, however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
    "\n",
    "The RNN returns 2 tensors, `output` of size _**[sentence length, batch size, hidden dim]**_ and `hidden` of size _**[1, batch size, hidden dim]**_. `output` is the concatenation of the hidden state from every time step, whereas `hidden` is simply the final hidden state. We verify this using the `assert` statement. Note the `squeeze` method, which is used to remove a dimension of size 1. \n",
    "\n",
    "Finally, we feed the last hidden state, `hidden`, through the linear layer, `fc`, to produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an instance of our RNN class. \n",
    "\n",
    "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size. \n",
    "\n",
    "The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
    "\n",
    "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
    "\n",
    "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a function that will tell us how many trainable parameters our model has so we can compare the number of parameters across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the training and then train the model.\n",
    "\n",
    "First, we'll create an optimizer. This is the algorithm we use to update the parameters of the module. Here, we'll use _stochastic gradient descent_ (SGD). The first argument is the parameters will be updated by the optimizer, the second is the learning rate, i.e. how much we'll change the parameters by when we do a parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define our loss function. In PyTorch this is commonly called a criterion. \n",
    "\n",
    "The loss function here is _binary cross entropy with logits_. \n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0 or 1, we want to restrict the predictions to a number between 0 and 1. We do this using the _sigmoid_ or _logit_ functions. \n",
    "\n",
    "We then use this this bound scalar to calculate the loss using binary cross entropy. \n",
    "\n",
    "The `BCEWithLogitsLoss` criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.to`, we can place the model and the criterion on the GPU (if we have one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our criterion function calculates the loss, however we have to write our function to calculate the accuracy. \n",
    "\n",
    "This function first feeds the predictions through a sigmoid layer, squashing the values between 0 and 1, we then round them to the nearest integer. This rounds any value greater than 0.5 to 1 (a positive sentiment) and the rest to 0 (a negative sentiment).\n",
    "\n",
    "We then calculate how many rounded predictions equal the actual labels and average it across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train` function iterates over all examples, one batch at a time. \n",
    "\n",
    "`model.train()` is used to put the model in \"training mode\", which turns on _dropout_ and _batch normalization_. Although we aren't using them in this model, it's good practice to include it.\n",
    "\n",
    "For each batch, we first zero the gradients. Each parameter in a model has a `grad` attribute which stores the gradient calculated by the `criterion`. PyTorch does not automatically remove (or \"zero\") the gradients calculated from the last gradient calculation, so they must be manually zeroed.\n",
    "\n",
    "We then feed the batch of sentences, `batch.text`, into the model. Note, you do not need to do `model.forward(batch.text)`, simply calling the model works. The `squeeze` is needed as the predictions are initially size _**[batch size, 1]**_, and we need to remove the dimension of size 1 as PyTorch expects the predictions input to our criterion function to be of size _**[batch size]**_.\n",
    "\n",
    "The loss and accuracy are then calculated using our predictions and the labels, `batch.label`, with the loss being averaged over all examples in the batch.\n",
    "\n",
    "We calculate the gradient of each parameter with `loss.backward()`, and then update the parameters using the gradients and optimizer algorithm with `optimizer.step()`.\n",
    "\n",
    "The loss and accuracy is accumulated across the epoch, the `.item()` method is used to extract a scalar from a tensor which only contains a single value.\n",
    "\n",
    "Finally, we return the loss and accuracy, averaged across the epoch. The `len` of an iterator is the number of batches in the iterator.\n",
    "\n",
    "You may recall when initializing the `LABEL` field, we set `dtype=torch.float`. This is because TorchText sets tensors to be `LongTensor`s by default, however our criterion expects both inputs to be `FloatTensor`s. Setting the `dtype` to be `torch.float`, did this for us. The alternative method of doing this would be to do the conversion inside the `train` function by passing `batch.label.float()` instad of `batch.label` to the criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evaluate` is similar to `train`, with a few modifications as you don't want to update the parameters when evaluating.\n",
    "\n",
    "`model.eval()` puts the model in \"evaluation mode\", this turns off _dropout_ and _batch normalization_. Again, we are not using them in this model, but it is good practice to include them.\n",
    "\n",
    "No gradients are calculated on PyTorch operations inside the `with no_grad()` block. This causes less memory to be used and speeds up computation.\n",
    "\n",
    "The rest of the function is the same as `train`, with the removal of `optimizer.zero_grad()`, `loss.backward()` and `optimizer.step()`, as we do not update the model's parameters when evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a function to tell us how long an epoch takes to compare training times between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
    "\n",
    "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 8m 33s\n",
      "\tTrain Loss: 0.694 | Train Acc: 50.23%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.59%\n",
      "Epoch: 02 | Epoch Time: 9m 24s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.85%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.83%\n",
      "Epoch: 03 | Epoch Time: 9m 0s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.15%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 50.67%\n",
      "Epoch: 04 | Epoch Time: 8m 57s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.70%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.43%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Kha lun tt nghip\\HKII\\Thy Bnh _ Kha lun\\Kin thc kha lun\\Demo Sentiment\\3.@bentrevett\\pytorch-sentiment-analysis\\1 - Simple Sentiment Analysis.ipynb Cell 50'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000050?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000050?line=6'>7</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000050?line=8'>9</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000050?line=9'>10</a>\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000050?line=11'>12</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32mf:\\Kha lun tt nghip\\HKII\\Thy Bnh _ Kha lun\\Kin thc kha lun\\Demo Sentiment\\3.@bentrevett\\pytorch-sentiment-analysis\\1 - Simple Sentiment Analysis.ipynb Cell 44'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000044?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, batch\u001b[39m.\u001b[39mlabel)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000044?line=15'>16</a>\u001b[0m acc \u001b[39m=\u001b[39m binary_accuracy(predictions, batch\u001b[39m.\u001b[39mlabel)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000044?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000044?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Kh%C3%B3a%20lu%E1%BA%ADn%20t%E1%BB%91t%20nghi%E1%BB%87p/HKII/Th%E1%BA%A7y%20B%C3%ACnh%20_%20Kh%C3%B3a%20lu%E1%BA%ADn/Ki%E1%BA%BFn%20th%E1%BB%A9c%20kh%C3%B3a%20lu%E1%BA%ADn/Demo%20Sentiment/3.%40bentrevett/pytorch-sentiment-analysis/1%20-%20Simple%20Sentiment%20Analysis.ipynb#ch0000044?line=21'>22</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\quyen\\myenv\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\quyen\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/quyen/myenv/lib/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which we'll improve in the next notebook.\n",
    "\n",
    "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.709 | Test Acc: 47.38%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook, the improvements we will make are:\n",
    "- packed padded sequences\n",
    "- pre-trained word embeddings\n",
    "- different RNN architecture\n",
    "- bidirectional RNN\n",
    "- multi-layer RNN\n",
    "- regularization\n",
    "- a different optimizer\n",
    "\n",
    "This will allow us to achieve ~84% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
